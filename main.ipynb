{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python library import area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch,numpy as np,torch.nn as nn,torch.nn.functional as F,torch.optim as optim,torchvision.models as models,torch.backends.cudnn as cudnn,torchvision.datasets as datasets,time,os,shutil,sys\n",
    "import xml\n",
    "\n",
    "from dataset_for_pascal import VOCDetection as VOC\n",
    "import dataset_for_pascal as dsStuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General setup area, change PATH_TRAIN and PATH_TEST. (classes if necessary, but lets not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Insert PATH of the datasets\"\n",
    "PATH_TRAIN = \"D:/VOCdevkit/VOC2007/\" #\"./\"\n",
    "PATH_TEST = \"D:/VOCtest/VOC2007/\" #./\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "classes = ('__background__',  # always index 0\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable',\n",
    "           'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor')\n",
    "grid=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch dataset area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myTrainDataset = VOC(\"D:/VOCdevkit/VOC2007/\",'2007','train',False,transforms=transforms.Compose([\n",
    "#     transforms.Resize((384,384)),transforms.ToTensor()#(384,384)\n",
    "# ]))\n",
    "#\n",
    "# myValDataset = VOC(\"D:/VOCdevkit/VOC2007/\",'2007','val',True,transforms=transforms.Compose([\n",
    "#     transforms.Resize((384,384)),transforms.ToTensor()\n",
    "# ]))\n",
    "\n",
    "\"dataset definition area\"\n",
    "myTrainValDataset = VOC(PATH_TRAIN,'2007','trainval',False,transforms=transforms.Compose([\n",
    "    transforms.Resize((384,384)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "\n",
    "myTestDataset = VOC(PATH_TEST,'2007','test',True,transforms=transforms.Compose([\n",
    "    transforms.Resize((384,384)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Potato Net setup area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PotatoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PotatoNet, self).__init__()\n",
    "        self.C=20\n",
    "        self.B=1\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.conv1= nn.Conv2d(3, 32, 5)\n",
    "        self.conv1_1= nn.Conv2d(32, 32, 3,padding=1)\n",
    "        self.conv2= nn.Conv2d(32, 128, 5)\n",
    "        self.conv2_1= nn.Conv2d(128, 128, 3,padding=1)\n",
    "        self.conv3= nn.Conv2d(128, 512, 5)\n",
    "        self.conv4= nn.Conv2d(512, 512, 5)\n",
    "        self.conv4_1= nn.Conv2d(512, 512, 3,padding=1)\n",
    "        self.conv5_1= nn.Conv2d(512, 1024, 3,padding=1)\n",
    "        self.conv6= nn.Conv2d(1024, self.B*(1+4+self.C), 7)\n",
    "\n",
    "        self.fc0 = nn.Linear(in_features=self.B*(1+4+self.C)*7*7, out_features=self.B*(1+4+self.C)*grid*grid)\n",
    "        self.fc1 = nn.Linear(in_features=self.B*(1+4+self.C)*grid*grid, out_features=grid*grid*self.B*(1+4+self.C))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"forward layer\"\n",
    "\n",
    "        \"residual block 1\"\n",
    "        x=self.pool2(self.conv1(x))\n",
    "        x=F.elu(self.conv1_1(x))\n",
    "        out=self.pool2(F.dropout(self.conv2(x), p=0.4, training=True))\n",
    "        x=F.relu(self.conv2_1(out))\n",
    "        x=F.relu(self.conv2_1(x))\n",
    "        x=self.pool2(F.dropout(self.conv3(x+out), p=0.5, training=True))\n",
    "\n",
    "        \"residual block 2\"\n",
    "        out=self.pool2(F.dropout(self.conv4(x), p=0.5, training=True))\n",
    "        x=F.relu(self.conv4_1(out))\n",
    "        x=F.relu(F.dropout(self.conv4_1(x), p=0.5, training=True))\n",
    "        x=F.relu(self.conv5_1(x))\n",
    "        x=self.pool2(F.dropout(self.conv6(x+F.elu(self.conv5_1(out))), p=0.5, training=True))\n",
    "\n",
    "        \"flatten\"\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x=self.fc0(x)\n",
    "        x=self.fc1(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy and Loss setup area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(real, pred):\n",
    "    \"\"\"\n",
    "    Calculates Cross_entropy via negative log likelihood.\n",
    "\n",
    "    IN: ground truth final layer, model prediction final layer\n",
    "    OUT: outputs\n",
    "\n",
    "    Taken from\n",
    "    https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    logs=-pred[(real == 1).nonzero()]+torch.log(torch.exp(pred).sum())\n",
    "    return logs\n",
    "\n",
    "def lossFunc(real,pred,classNo=20):\n",
    "    \"\"\"\n",
    "    calculates loss.\n",
    "    IN: ground truth final layer, model prediction final layer\n",
    "    OUT: mean loss\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for eachTensor in range(len(pred)):\n",
    "        each=0\n",
    "        while each < len(pred[eachTensor]):\n",
    "            if real[eachTensor][each]==0:\n",
    "                pred[eachTensor][each+1:each+4+classNo+1]=0\n",
    "            each+=5+classNo\n",
    "\n",
    "    loss=(pred-real)**2\n",
    "\n",
    "    for eachTensor in range(len(loss)):\n",
    "        each=0\n",
    "        while each < len(loss[eachTensor]):\n",
    "\n",
    "            if real[eachTensor][each]==1:\n",
    "                wght=crossEntropy(real[eachTensor][each+1+4:each+4+classNo+1], pred[eachTensor][each+1+4:each+4+classNo+1])\n",
    "                loss[eachTensor][each+1+4:each+4+classNo+1]=wght\n",
    "\n",
    "            each+=5+classNo\n",
    "\n",
    "    loss=loss.mean()\n",
    "\n",
    "\n",
    "    if loss>10:\n",
    "        print(\"RIP\",loss)\n",
    "        print(pred,real)\n",
    "        exit()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation mAP (change startCount and endCount) and test mAP (change totalImage) function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validationMAP(N):\n",
    "    \"\"\"\n",
    "    calculates validation mAP\n",
    "    IN: model itself\n",
    "    OUT: Bool, whether the model is up to standard or scheduling/mid-process final tuning is needed.\n",
    "    \"\"\"\n",
    "    sumofiou=0\n",
    "    sumofnonzero=0\n",
    "    totaldetected=0\n",
    "    maxof=0\n",
    "    totObjSum=0\n",
    "    mAP50=0\n",
    "    mAP75=0\n",
    "    classMatchCount=0\n",
    "\n",
    "    startCount=0#len(myTrainValDataset)-500\n",
    "    endCount=5#len(myTrainValDataset)\n",
    "\n",
    "    print(\"total tested images:\",endCount-startCount)\n",
    "    for each in range(startCount,endCount):\n",
    "\n",
    "        x,t, wh, imgRaw, totalObjCount = myTrainValDataset.__getitem__(each)\n",
    "        x,t = x.to(device), torch.FloatTensor(t).to(device).unsqueeze(0)\n",
    "        p = N(x.unsqueeze(0))\n",
    "        p,t=p.squeeze(0),t.squeeze(0)\n",
    "\n",
    "        totObjSum+=totalObjCount\n",
    "        obtained=myTrainValDataset.iou(t,p.cpu().data.numpy())\n",
    "\n",
    "        for each in obtained:\n",
    "            sumofiou+=each[0]\n",
    "            if each[0]>maxof:\n",
    "                maxof=each[0]\n",
    "            if each[0]>0.5:\n",
    "                mAP50+=1\n",
    "            if each[0]>0.75:\n",
    "                mAP75+=1\n",
    "            if each[3]:\n",
    "                classMatchCount+=1\n",
    "        totaldetected+=len(obtained)\n",
    "\n",
    "\n",
    "    if totaldetected>0:\n",
    "        print(\"total detected obj:\",totaldetected,\"| average per detected box %:\",(sumofiou*100)/totaldetected)\n",
    "        print(\"max iou %:\",maxof*100)\n",
    "        mAPP=sumofiou/totObjSum\n",
    "        print(\"total object amount:\",totObjSum,\"| mAP %:\",mAPP*100)\n",
    "        print(\"mAP50 %:\",mAP50/totObjSum,\"| mAP75 %:\",mAP75/totObjSum)\n",
    "        print(\"correctClass %\",classMatchCount/totObjSum)\n",
    "\n",
    "        \"uncomment to allow saving or decide the requirements or any.\"\n",
    "        # save\n",
    "        # if mAPP*100>8:\n",
    "        #     torch.save(N.state_dict(), \"./\"+str(mAPP)[:6].strip(\".\")+\"state.m\")\n",
    "        #     torch.save(N, \"./\"+str(mAPP)[:6].strip(\".\")+\"model.m\")\n",
    "\n",
    "        if mAPP*100<7:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        print(\"none detected\")\n",
    "        return True\n",
    "\n",
    "\n",
    "\"final overload test\"\n",
    "def testMAP(N):\n",
    "\n",
    "    \"\"\"\n",
    "    calculates test mAP\n",
    "    IN: model itself\n",
    "    OUT: None\n",
    "    \"\"\"\n",
    "    sumofiou=0\n",
    "    sumofnonzero=0\n",
    "    totaldetected=0\n",
    "    maxof=0\n",
    "    totObjSum=0\n",
    "    mAP50=0\n",
    "    mAP75=0\n",
    "    classMatchCount=0\n",
    "\n",
    "    totalImage=5#len(myTestDataset)\n",
    "\n",
    "    print(\"total tested:\",totalImage)\n",
    "    for each in range(totalImage):\n",
    "        try:\n",
    "            x,t, wh, imgRaw, totalObjCount = myTestDataset.__getitem__(each)\n",
    "            x,t = x.to(device), torch.FloatTensor(t).to(device)\n",
    "            p = N(x.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "            totObjSum+=totalObjCount\n",
    "            obtained=myTestDataset.iou(t,p.cpu().data.numpy())\n",
    "\n",
    "            for each in obtained:\n",
    "                sumofiou+=each[0]\n",
    "                if each[0]>maxof:\n",
    "                    maxof=each[0]\n",
    "                if each[0]>0.5:\n",
    "                    mAP50+=1\n",
    "                if each[0]>0.75:\n",
    "                    mAP75+=1\n",
    "                if each[3]:\n",
    "                    classMatchCount+=1\n",
    "            totaldetected+=len(obtained)\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if totaldetected>0:\n",
    "        print(\"total detected obj:\",totaldetected,\"| average per detected box %:\",(sumofiou*100)/totaldetected)\n",
    "        print(\"max iou %:\",maxof*100)\n",
    "        mAPP=sumofiou/totObjSum\n",
    "        print(\"total object amount:\",totObjSum,\"| mAP %:\",mAPP*100)\n",
    "        print(\"mAP50 %:\",mAP50/totObjSum,\"| mAP75 %:\",mAP75/totObjSum)\n",
    "        print(\"correctClass %\",classMatchCount/totObjSum)\n",
    "\n",
    "    else:\n",
    "        print(\"none detected\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training / Testing area. change isTest to change the functions, or hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "total tested images: 5\n",
      "none detected\n",
      "loss 0.7507082551717759\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 1\n",
      "total tested images: 5\n",
      "none detected\n",
      "loss 0.7419617265462876\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 2\n",
      "total tested images: 5\n",
      "total detected obj: 5 | average per detected box %: 0.0\n",
      "max iou %: 0\n",
      "total object amount: 24 | mAP %: 0.0\n",
      "mAP50 %: 0.0 | mAP75 %: 0.0\n",
      "correctClass % 0.0\n",
      "loss 0.7028183609247207\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 3\n",
      "total tested images: 5\n",
      "total detected obj: 9 | average per detected box %: 9.001722724901306\n",
      "max iou %: 44.58448886871338\n",
      "total object amount: 24 | mAP %: 3.3756460218379893\n",
      "mAP50 %: 0.0 | mAP75 %: 0.0\n",
      "correctClass % 0.0\n",
      "loss 0.6238440603017807\n",
      "------------------------------------------------------\n",
      "\n",
      "epoch 4\n",
      "total tested images: 5\n",
      "total detected obj: 9 | average per detected box %: 11.46720958252748\n",
      "max iou %: 37.85082697868347\n",
      "total object amount: 24 | mAP %: 4.3002035934478045\n",
      "mAP50 %: 0.0 | mAP75 %: 0.0\n",
      "correctClass % 0.041666666666666664\n",
      "loss 0.6002412021160126\n",
      "------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "isTest: \"True, if want to use test dataset. False, if train\"\n",
    "\n",
    "Note to lecturer: I ran this test method only once or twice to write the evaluation section.\n",
    "I used the eval dataset instead.\n",
    "\n",
    "\"\"\"\n",
    "isTest=False\n",
    "\n",
    "if isTest:\n",
    "    \"Test area\"\n",
    "    N = PotatoNet().to(device)\n",
    "    \"insert other models?\"\n",
    "    N.load_state_dict(torch.load(\"./Multi-PotatoNet_state.m\"))\n",
    "    N.eval()\n",
    "    testMAP(N)\n",
    "\n",
    "else:\n",
    "    \"training\"\n",
    "\n",
    "    N = PotatoNet().to(device)\n",
    "\n",
    "    \"hyper parameters\"\n",
    "    lr=0.01\n",
    "    wd=0.0005\n",
    "    momentum=0.05\n",
    "    epochTOTAL=5#30\n",
    "    optimiser = torch.optim.SGD(N.parameters(), lr=lr, weight_decay=wd,momentum=momentum)\n",
    "    totalImageTrain=10#(len(myTrainValDataset)-500)\n",
    "\n",
    "    epoch = 0\n",
    "    while (epoch<epochTOTAL):\n",
    "        print(\"epoch\",epoch)\n",
    "\n",
    "        # arrays for metrics\n",
    "        logs = {}\n",
    "        train_loss_arr = np.zeros(0)\n",
    "\n",
    "        N = N.train()\n",
    "        # train\n",
    "        \n",
    "        for i in range(totalImageTrain):\n",
    "            x,t,b,r,n = myTrainValDataset.__getitem__(i)\n",
    "            xNew,tNew=dsStuff.horzFlip(x.clone(),t.copy(),1)\n",
    "            xNew,tNew=xNew.to(device).unsqueeze(0), torch.FloatTensor(tNew).to(device)\n",
    "            x,t = x.to(device), torch.FloatTensor(t).to(device)\n",
    "\n",
    "            optimiser.zero_grad()\n",
    "            x = torch.cat((x.unsqueeze(0), xNew), 0)\n",
    "            t=torch.cat((t.unsqueeze(0),tNew.unsqueeze(0)),0)\n",
    "            p = N(x).squeeze(0)\n",
    "            loss = lossFunc(t,p)\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "\n",
    "\n",
    "            if i==500 or i==1500 or i==2500 or i == 3500:\n",
    "                print(\"i:\",i)\n",
    "\n",
    "        N = N.eval()\n",
    "\n",
    "        \"this is the eval I used\"\n",
    "        validationMAP(N)\n",
    "\n",
    "        print('loss', train_loss_arr.mean())\n",
    "        print(\"------------------------------------------------------\")\n",
    "        print()\n",
    "        epoch = epoch+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets draw images (can change the numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "------------\n",
      "IoU per detected box 38.99517059326172\n",
      "Top-1? True\n",
      "------------\n",
      "IoU per detected box 54.18853163719177\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 37.920719385147095\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 29.261747002601624\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 6.031519174575806\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 33.43227207660675\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 35.018759965896606\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 45.43057680130005\n",
      "Top-1? False\n",
      "------------\n",
      "IoU per detected box 9.207733720541\n",
      "Top-1? False\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "\"some bounding boxes from test\"\n",
    "M = PotatoNet().to(device)\n",
    "\"insert any other state?\"\n",
    "M.load_state_dict(torch.load(\"./Multi-PotatoNet_state.m\"))\n",
    "M.eval()\n",
    "print(\"------------\")\n",
    "print(\"------------\")\n",
    "for each in [0,10,50,100,200,500,1000,2000,4500]:\n",
    "    x,t, wh, imgRaw, totalObjCount = myTestDataset.__getitem__(each)\n",
    "    x,t = x.to(device), torch.FloatTensor(t).to(device)\n",
    "    p = M(x.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "    myTestDataset.drawImages(t,p.cpu().data.numpy(),wh,imgRaw)\n",
    "\n",
    "    obtained=myTestDataset.iou(t,p.cpu().data.numpy())\n",
    "    try:\n",
    "        print(\"IoU per detected box\",obtained[0][0]*100)\n",
    "        print(\"Top-1?\",obtained[0][3])\n",
    "        print(\"------------\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
